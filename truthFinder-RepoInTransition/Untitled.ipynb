{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# truth-finder\n",
    "\n",
    "## Description\n",
    "Due to the increasing amount of 'fake news' being spread on the internet, it is vital that we start to develop methods\n",
    "to sift through texual articles and authenticate the credibility of the information in them.\n",
    " \n",
    "The purpose of this program is to evaluate the validity of a given textual claim and be able to provide an explanation as to why the information is true or false.\n",
    "It accomplishes this task by querying the claim in a search engine and assessing the articles that either support or refute the claim. It then inteligently reads and evauluates the credibility of the supporting and refuting articles. To make it's final classification it aggregates the overall 'opinion' it has found across the articles weighting the opinions by it's derived opinion of source reliability. The texual explanation is the most relevent snippet of text from one of the articles which had the 'correct' opinion regarding the claim. \n",
    "\n",
    "\n",
    "The program is based off of the techniques proposed by Popat et. al [[1](#References)] in \"Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media\".\n",
    "\n",
    "## Example Queries\n",
    "\n",
    "query: \"Obama was born in Kenya\"\n",
    "\n",
    "![query1](imgs/query1.png)\n",
    "\n",
    "## Dependancies\n",
    "- Python 3.6+\n",
    "- googlesearch\n",
    "- BeautifulSoup (bs4)\n",
    "- NLTK\n",
    "  - PorterStemmer\n",
    "\n",
    "- liblinear\n",
    "  - https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Using pre-trained models\n",
    "\n",
    "I have included model weights that I have trained in the resources folder.\n",
    " \n",
    "python truth-finder.py\n",
    "\n",
    "\n",
    "### Training new models\n",
    "\n",
    "Traing new models is more complicated as you must first aquire and process\n",
    "the neccessary data for the models. Please read the [Data](#Data) section Prior to performing these steps.\n",
    "\n",
    "\n",
    "python -m train_stance --featPath resources/stance/stanceFeats.pickle --dataPath resources/snopesData -- stancePath resources/stance/stance.model\n",
    "\n",
    "## Data\n",
    "\n",
    "\n",
    "## References\n",
    "<a id=\"1\">[1]</a> \n",
    "Kashyap Popat. et. al (2017).\n",
    "Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media<br>\n",
    "Proceedings of the 26th International Conference on World Wide Web Companion, April 03-07 <br>\n",
    "https://resources.mpi-inf.mpg.de/impact/web_credibility_analysis/www2017_popat.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
